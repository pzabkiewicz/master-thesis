{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import scikit_posthocs as posthocs\n",
    "\n",
    "picklepath = '../mainexperiment-results/results.pickle'\n",
    "cols = ['zoning', 'edge_maps', 'zoning_chain_code', 'local_binary_pattern'] # column names for box plots\n",
    "\n",
    "cmap = ['1', '#fb6a4a',  '#08306b',  '#4292c6', '#c6dbef']\n",
    "heatmap_args = {'cmap': cmap, 'linewidths': 0.25, 'linecolor': '0.5', 'clip_on': False, 'square': True, 'cbar_ax_bbox': [0.80, 0.35, 0.04, 0.3]}\n",
    "\n",
    "with open(picklepath, 'rb') as f:\n",
    "    results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def tests_for_normality(accuracy_results):\n",
    "    \"\"\" Perfroms Shapiro-Wilk test for checking if all accuracy results \n",
    "        (for every feature extraction method) obtained using one classifier \n",
    "        come from normal distribution. \n",
    "        \n",
    "        :params \n",
    "            accuracy_results dictionary \n",
    "                feature_extraction_method: 1 x N array\n",
    "            \n",
    "        :returns \n",
    "            list with p values for each sample \"\"\"\n",
    "    \n",
    "    p_values = []\n",
    "    for res in list(accuracy_results.values()):\n",
    "        p = stats.shapiro(res)\n",
    "        p_values.append(p[1])\n",
    "    \n",
    "    return np.array(p_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def calculate_mean_and_se(samples_from_classifier):\n",
    "    \"\"\" Calculates mean and 0.95 SE from sample (feature extraction method) obtained with one classifier \n",
    "    \n",
    "    :params\n",
    "        sample_from_classifier dictionary where key - feature extraction method, value - list of sample results \n",
    "    \n",
    "    :returns\n",
    "        stats array where row corresponds any feature exctraction method and column[0] mean and column[1] 0.95 SE \"\"\"\n",
    "\n",
    "    stats = np.zeros((4,2))\n",
    "    for k, (feature_extraction_method, sample_results) in enumerate(samples_from_classifier.items()):\n",
    "        mu = np.mean(sample_results)\n",
    "        se = np.std(sample_results) / sqrt(len(sample_results)) * 0.95\n",
    "        stats[k, 0] = mu\n",
    "        stats[k, 1] = se\n",
    "    \n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def show_mean_se_plot(clf_results):\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(10, 5)\n",
    "\n",
    "    minor_ticks = np.linspace(0.0, 1.0, 21)\n",
    "    ax.set_yticks(minor_ticks, minor=True)\n",
    "\n",
    "    ax.grid(which='minor', alpha=0.2)\n",
    "    ax.grid(which='major', alpha=0.5)\n",
    "    ax.grid(True)\n",
    "\n",
    "    plt.errorbar(x=cols, y=clf_results[:,0], yerr=clf_results[:,1], fmt='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# means for groups \n",
    "for clf, fem_results in results.items():\n",
    "    print()\n",
    "    for feature_extraction_methods, result in fem_results.items():\n",
    "        res = np.array(result)\n",
    "        print(clf, feature_extraction_methods, np.mean(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test for normality of each sample SVM\n",
    "svm_results = results['svm']\n",
    "svm_p_values = tests_for_normality(svm_results)\n",
    "\n",
    "print(\"All samples evaluated with svm come from normal distribution: \", np.all(svm_p_values > 0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "svm_stats = calculate_mean_and_se(svm_results)\n",
    "show_mean_se_plot(svm_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = np.array([svm_results[cols[0]], \n",
    "                 svm_results[cols[1]],\n",
    "                 svm_results[cols[2]],\n",
    "                 svm_results[cols[3]]])\n",
    "\n",
    "df = pd.DataFrame(data.T, columns=cols)\n",
    "plt.figure(figsize=(10, 5))\n",
    "df.boxplot()\n",
    "plt.savefig('svm-boxplot.eps', format='eps', dpi=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Kruskal-Wallis non-parametric test for SVM\n",
    "stats.mstats.kruskalwallis(svm_results[cols[0]],\n",
    "                           svm_results[cols[1]],\n",
    "                           svm_results[cols[2]],\n",
    "                           svm_results[cols[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Kurskal-Wallis test rejected null hypothesis\n",
    "# post hoc test for SVM\n",
    "df_melt = pd.melt(df, value_vars=cols)\n",
    "svm_posthoc_results = posthocs.posthoc_conover(df_melt, val_col='value', group_col='variable', p_adjust='holm')\n",
    "\n",
    "# Format: diagonal, non-significant, p<0.001, p<0.01, p<0.05\n",
    "posthocs.sign_plot(svm_posthoc_results, **heatmap_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test for normality of each sample KNN\n",
    "knn_results = results['knn']\n",
    "knn_p_values = tests_for_normality(knn_results)\n",
    "\n",
    "print(\"All samples evaluated with knn come from normal distribution: \", np.all(knn_p_values > 0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "knn_stats = calculate_mean_and_se(knn_results)\n",
    "show_mean_se_plot(knn_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = np.array([knn_results[cols[0]], \n",
    "                 knn_results[cols[1]],\n",
    "                 knn_results[cols[2]],\n",
    "                 knn_results[cols[3]]])\n",
    "\n",
    "df = pd.DataFrame(data.T, columns=cols)\n",
    "plt.figure(figsize=(10, 5))\n",
    "df.boxplot()\n",
    "plt.savefig('knn-boxplot.eps', format='eps', dpi=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# one way ANOVA for KNN\n",
    "stats.f_oneway(knn_results[cols[0]],\n",
    "               knn_results[cols[1]],\n",
    "               knn_results[cols[2]],\n",
    "               knn_results[cols[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test for equality of variances of each sample KNN\n",
    "stats.bartlett(knn_results[cols[0]],\n",
    "               knn_results[cols[1]],\n",
    "               knn_results[cols[2]],\n",
    "               knn_results[cols[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# post hoc test for KNN\n",
    "# bartlett test does not reject null hypothesis, hence we can use pairwise ttest\n",
    "df_melt = pd.melt(df, value_vars=cols)\n",
    "knn_posthoc_results = posthocs.posthoc_ttest(df_melt, val_col='value', group_col='variable', p_adjust='holm')\n",
    "\n",
    "# Format: diagonal, non-significant, p<0.001, p<0.01, p<0.05\n",
    "posthocs.sign_plot(knn_posthoc_results, **heatmap_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test for normality of each sample MLP\n",
    "mlp_results = results['mlp']\n",
    "mlp_p_values = tests_for_normality(mlp_results)\n",
    "\n",
    "print(\"All samples evaluated with mlp come from normal distribution: \", np.all(mlp_p_values > 0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mlp_stats = calculate_mean_and_se(mlp_results)\n",
    "show_mean_se_plot(mlp_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = np.array([mlp_results[cols[0]], \n",
    "                 mlp_results[cols[1]],\n",
    "                 mlp_results[cols[2]],\n",
    "                 mlp_results[cols[3]]])\n",
    "\n",
    "df = pd.DataFrame(data.T, columns=cols)\n",
    "plt.figure(figsize=(10, 5))\n",
    "df.boxplot()\n",
    "plt.savefig('mlp-boxplot.eps', format='eps', dpi=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# one way ANOVA for MLP\n",
    "stats.f_oneway(mlp_results[cols[0]], \n",
    "               mlp_results[cols[1]],\n",
    "               mlp_results[cols[2]],\n",
    "               mlp_results[cols[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test for equality of variances of each sample MLP\n",
    "stats.bartlett(mlp_results[cols[0]], \n",
    "               mlp_results[cols[1]],\n",
    "               mlp_results[cols[2]],\n",
    "               mlp_results[cols[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# post hoc test for MLP\n",
    "# bartlett test does not reject null hypothesis, hence we can use pairwise ttest\n",
    "df_melt = pd.melt(df, value_vars=cols)\n",
    "mlp_posthoc_results = posthocs.posthoc_ttest(df_melt, val_col='value', group_col='variable', p_adjust='holm')\n",
    "\n",
    "# Format: diagonal, non-significant, p<0.001, p<0.01, p<0.05\n",
    "posthocs.sign_plot(mlp_posthoc_results, **heatmap_args)\n",
    "plt.savefig('p-value.eps', format='eps', dpi=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
